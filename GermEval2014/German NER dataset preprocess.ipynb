{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GermEval 2014 (German NER) 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './data/NER-de-train.tsv'\n",
    "dev_file = './data/NER-de-dev.tsv'\n",
    "test_file = './data/NER-de-test.tsv'\n",
    "raw_files = ['./data/NER-de-train.tsv', './data/NER-de-dev.tsv', './data/NER-de-test.tsv']\n",
    "save_files = ['./data/train.txt', './data/dev.txt', './data/test.txt']\n",
    "label_file = './data/labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始数据有四列 (使用 tab 分割)，预处理程序只是处理两个相关的列 (token and outer span NER annotation)。\n",
    "\n",
    "```shell\n",
    "curl -L 'https://sites.google.com/site/germeval2014ner/data/NER-de-train.tsv?attredirects=0&d=1' \\\n",
    "| grep -v \"^#\" | cut -f 2,3 | tr '\\t' ' ' > train.txt.tmp\n",
    "curl -L 'https://sites.google.com/site/germeval2014ner/data/NER-de-dev.tsv?attredirects=0&d=1' \\\n",
    "| grep -v \"^#\" | cut -f 2,3 | tr '\\t' ' ' > dev.txt.tmp\n",
    "curl -L 'https://sites.google.com/site/germeval2014ner/data/NER-de-test.tsv?attredirects=0&d=1' \\\n",
    "| grep -v \"^#\" | cut -f 2,3 | tr '\\t' ' ' > test.txt.tmp\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrac_columns(fp):\n",
    "    lines = []\n",
    "    with open(fp, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            if line == '\\n':\n",
    "                lines.append(line)\n",
    "            else:\n",
    "                items = line.split('\\t')\n",
    "                if len(items) == 4:\n",
    "                    lines.append('{} {}'.format(items[1], items[2]))\n",
    "                else:\n",
    "                    continue\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GermEval 2014 数据集包含一些特殊的控制字符： `'\\x96', '\\u200e', '\\x95', '\\xad' or '\\x80'`。这些 tokens 在 `BertTokenizer` 中不存在，会返回空 token ，使得与输入 `InputExample` 不一致。\n",
    "\n",
    "因此需要过滤这些 tokens ，将长句子分割成短句子。\n",
    "\n",
    "\n",
    "```shell\n",
    "wget \"https://raw.githubusercontent.com/stefan-it/fine-tuned-berts-seq/master/scripts/preprocess.py\"\n",
    "```\n",
    "\n",
    "定义变量:\n",
    "\n",
    "```shell\n",
    "export MAX_LENGTH=128\n",
    "export BERT_MODEL=bert-base-multilingual-cased\n",
    "\n",
    "python3 preprocess.py train.txt.tmp $BERT_MODEL $MAX_LENGTH > train.txt\n",
    "python3 preprocess.py dev.txt.tmp $BERT_MODEL $MAX_LENGTH > dev.txt\n",
    "python3 preprocess.py test.txt.tmp $BERT_MODEL $MAX_LENGTH > test.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fun(lines, max_len=128):\n",
    "    text = []\n",
    "    subword_len_counter = 0  # 用于标记句子的长度\n",
    "    for line in lines:\n",
    "        line = line.rstrip()\n",
    "        # 如果为空行，初始化句子长度为 0\n",
    "        if not line:\n",
    "            text.append(line)\n",
    "            subword_len_counter = 0\n",
    "            continue\n",
    "\n",
    "        token = line.split()[0]\n",
    "        current_subwords_len = len(tokenizer.tokenize(token))\n",
    "\n",
    "        # Token contains strange control characters like \\x96 or \\x95\n",
    "        # Just filter out the complete line\n",
    "        if current_subwords_len == 0:\n",
    "            continue\n",
    "\n",
    "        if (subword_len_counter + current_subwords_len) > max_len:\n",
    "            text.append(\"\")\n",
    "            text.append(line)\n",
    "            subword_len_counter = 0\n",
    "            continue\n",
    "\n",
    "        subword_len_counter += current_subwords_len\n",
    "\n",
    "        text.append(line)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_txt(fp, text):\n",
    "    with open(fp, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rfp, sfp in zip(raw_files, save_files):\n",
    "    print(rfp, sfp)\n",
    "    lines = extrac_columns(rfp)\n",
    "    text = clean_fun(lines, max_len=128)\n",
    "    save_txt(sfp, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrac_labels(fps, label_fp):\n",
    "    labels = set()\n",
    "    for fp in fps:\n",
    "        with open(fp, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.rstrip()\n",
    "                # 如果为空行，初始化句子长度为 0\n",
    "                if line:\n",
    "                    label = line.split()[1]\n",
    "                    labels.add(label)\n",
    "    with open(label_fp, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(labels))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrac_labels(save_files, label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
